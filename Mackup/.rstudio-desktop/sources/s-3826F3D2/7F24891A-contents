---
title: "Bayes Network - Project 1"
output:
  pdf_document: default
  html_document:
    df_print: paged
---
```{r}
library(dplyr)
library(dagitty)
library(Hmisc)
#library(caTools)
library(bnlearn)
library( pROC )
```


```{r}
#Change the work directory to your location of th data
setwd(getwd())
```


# Importing & Clean Data
Original data is available at https://archive.ics.uci.edu/ml/datasets/Heart+Disease. 
## Import only cleveland data
The original data consist of data from 4 different hospitals in Hungarian, Switserland, Long Beach and Cleveland. In earlier research, the latter is used most research and contains the least missing values of the variables of interest. We thus use this data for our research.
```{r}
# load csv
a.all <- read.csv("data/all_processed.csv",header=TRUE,stringsAsFactors=FALSE) #colClasses=rep("double",4),
d <- read.csv("data/dataCleveland.csv",header=TRUE,stringsAsFactors=FALSE)
```

As missing values are present, we need to clear missing data & and subselect the variables of interest, based on own research. This results in 11 variables (including the target variable). The variables of interest are:
- Age (discrete)
- Sex (binary)
- Chest pain type (categorical) 
- Fasting blood sugar > 120 mg/dl (binary)
- Resting blood pressure (discrete)
- Serum cholesterol in mg/dl (discrete)
- Amount cigarettes/day (discrete)
- Number of years as a smoker (discrete)
- Cardiac fluoroscopy (categorical)
- Thalium stress test (categorical)
- Presence heart disease (categorical)


```{r}
#Select right variables
subset <- select(d, 3,4,9,16,10,12,14,15,44,51,58)

#Filter out mising values
prep <- filter(subset, age != -9 &  sex != -9 & cp != -9 &fbs != -9 & trestbps!= -9 & chol != -9 &cigs != -9 &years!= -9 & ca != -9 &thal != -9 &num!= -9 )
nrow(prep)
nrow(subset)
```




## Process Data
We first take a look at the distribution of the continuous variables of interest
```{r}
hist(prep$age)
hist(prep$chol)
hist(prep$cigs)
hist(prep$years)
hist(prep$trestbps)
```

As we can see, the range of the continuous variables are quite large. As we will use the _localTests_ function to optimize the network, it will use the chi square test. With 272 samples, the chi square test - which treats data as categorical data - introduces sparseness into the data, which is visualized below. Here, the occurences of the combination of all values from age (continuous) and ca (categorical) are shown. 


```{r}
#table( prep$age, prep$ca)
```
Thus, we have more table entries than we have data points, which is a problem for the chi square test. For this reason, we will bin the data of the continuous variables. As we see from the histograms, the variables do not follow a normal distribution. Because of this, we choose an equal amount of samples in each bin. We choose a bin size of 3. 
 
```{r}
#Bin continuous data into categorical data of 3 bins.
amountBins <- 3

continuousVars <- list("age", "chol", "cigs", "years","trestbps")
continuousVars <- unlist(continuousVars)
for(i in 1:length(continuousVars)){
  varname <- continuousVars[i]
  intervalValues.varname <- list()
  intervals.varname <-  names(split(prep, cut2(prep[[varname]], g=amountBins)))
  
  for(j in 1:length(intervals.varname)){
    
    intervals.t <-  unlist(strsplit(intervals.varname[j], ','))
    intervals.fst <- intervals.t[1]
    intervals.snd <- intervals.t[2]
    nc.1 <- nchar(intervals.fst)
    nc.2 <- nchar(intervals.snd)
    intervalValues.varname <- append(intervalValues.varname, as.numeric(substr(intervals.fst,2,nc.1)))
    intervalValues.varname <- append(intervalValues.varname, as.numeric(substr(intervals.snd,1,nc.2-1)))
    
  }
  intervalValues.varname <- unique(unlist(intervalValues.varname))
  intervalValues.varname <- intervalValues.varname[!is.na(intervalValues.varname)]
  intervalValues.varname[1] = intervalValues.varname[1]-1
  intervalValues.varname[length(intervalValues.varname)] = intervalValues.varname[length(intervalValues.varname)]+1
  
  colname.D <-  paste(varname, ".discrete",sep="")
  colname.N <- paste(varname, ".numeric", sep = "")
  prep[colname.D] <- cut( prep[[varname]], breaks=c(intervalValues.varname))
  prep[colname.N] <- as.numeric( prep[[colname.D]])
}

#prep

```

As we want to do an inference task, we split our data into a test- and training dataset.
```{r}
set.seed(13)

#Select only variables we need (numeric)

data <- select(prep, 2,3,4,9,10, 11,13,15,17,19,21)


# split the data 
smp_size = floor(0.75 *  nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <-  data[train_ind,]
test <- data[-train_ind,]


#test

```

As the inferences task includes predicting the prevalence of a heart disease, it is important to look at the final label. In this case, it is a multi-classification problem with 4 unique labels. However, as denoted in the background information of the dataset, 0 indicates the absences of a heart disease and [1-4] denote levels of presence of a heart disease. To improve the performance of the inference task, we therefore make it a binary classification problem by merging [1-4] to just value 1. This means that we create a binary test & training dataset
```{r}
num.binary <- prep$num
prep$num.binary <- rapply(as.list(num.binary), function(x) ifelse(x!=0, 1,x), how = "replace")

#Select only variables we need (numeric)
data.binary <- select(prep, 2,3,4,9,10,13,15,17,19,21)
data.binary$num.binary <- as.double(prep[,22])


head(data.binary)
train.binary <-  data.binary[train_ind,]
test.binary <- data.binary[-train_ind,]

#test.binary
```

We then calculate parameters of test and training set.
```{r}
data.neg = sum(data.binary$num.binary==0)
data.pos = sum(data.binary$num.binary==1)
train_neg = sum(train.binary$num.binary==0)
train_pos = sum(train.binary$num.binary==1)
test_neg = sum(test.binary$num.binary==0)
test_pos = sum(test.binary$num.binary==1)
train_pos_perc = train_pos/(train_neg+train_pos)
test_pos_perc = test_pos/(test_neg+test_pos)
data_pos_perc = data.pos/(data.neg+data.pos)
print(train_pos_perc)
print(test_pos_perc)
print(data_pos_perc)
```


# Create Model
To show the improvement in the inference task's performance by binarizing the target variable, both the Binary model as the multi-class classification model are included. The process of creating the model is described in the corresponding report.

## Binary Model

### Draw DAG
```{r}
#Make DAG
g.binary <- dagitty('
dag {
age.numeric [pos="0.262,-1.314"]
ca [pos="-1.351,0.555"]
chol.numeric [pos="-0.728,0.191"]
cigs.numeric [pos="-1.247,-0.466"]
cp [pos="0.348,-0.221"]
fbs [pos="-0.121,0.178"]
num.binary [pos="-0.667,1.153"]
sex [pos="-1.310,-1.357"]
thal [pos="-0.962,0.539"]
trestbps.numeric [pos="-1.247,0.178"]
years.numeric [pos="-0.270,-0.496"]
age.numeric -> cigs.numeric
age.numeric -> years.numeric
age.numeric -> trestbps.numeric
age.numeric -> num.binary
age.numeric -> ca
age.numeric -> chol.numeric
ca -> num.binary
chol.numeric -> num.binary
chol.numeric <-> trestbps.numeric
cigs.numeric -> chol.numeric
cigs.numeric -> cp
cigs.numeric -> fbs
cigs.numeric -> trestbps.numeric
cigs.numeric <-> years.numeric
cp -> num.binary
fbs -> num.binary
sex -> cigs.numeric
sex -> cp
sex -> thal
thal -> cp
sex -> years.numeric
thal -> num.binary
trestbps.numeric -> ca
trestbps.numeric -> cp
trestbps.numeric -> thal
years.numeric -> chol.numeric
years.numeric -> fbs
years.numeric -> trestbps.numeric
}
')

# plot causal diagram
plot(g.binary)

```



### Calculate local test
With the _localTests_ function, we look into the significant conditional (in)dependence between the variables of the causal graph _g.binary_.


```{r}
localTests(g.binary,prep,type="cis.chisq", max.conditioning.variables=3)
```
Here, we perform a _chi square_ test to reject or accept the null hypothesis (H_0). In this case, we can state that:
- H_0: Variable A and B (given variables [X,...,N]) are ***conditionally independent***
- H_1: Variable A and B (given variables [X,...,N]) are ***conditionally dependent***

When the p-value is below 0.05, we can say that there is a 5% chance that the H_0 is valid for the given data. In this case, we want to ***prove*** conditionally independency between the variables. Thus we want a p-value > 0.05 in order to accept the H_0.

Looking at the results, the p-value of all the local independencies, conditioned on a maximum of 3 variables, is higher than 0.05. The only exception is age _||_ sex, which - we think - is due to binning the data, as will be discussed later. 

It is also important to look at the RMSEA (Root Mean Square Error..)....

#### Compare binned data with non-binned data
Below, we can see the result of not binning the data to the p-value and the RMSEA value.

```{r}
#Make DAG
g.notbinned <- dagitty('
dag {
age [pos="0.262,-1.314"]
ca [pos="-1.351,0.555"]
chol [pos="-0.728,0.191"]
cigs [pos="-1.247,-0.466"]
cp [pos="0.348,-0.221"]
fbs [pos="-0.121,0.178"]
num.binary [pos="-0.667,1.153"]
sex [pos="-1.310,-1.357"]
thal [pos="-0.962,0.539"]
trestbps [pos="-1.247,0.178"]
years [pos="-0.270,-0.496"]
age -> cigs
age -> years
age -> trestbps
age -> num.binary
age -> ca
age -> chol
ca -> num.binary
chol -> num.binary
chol <-> trestbps
cigs -> chol
cigs -> cp
cigs -> fbs
cigs -> trestbps
cigs <-> years
cp -> num.binary
fbs -> num.binary
sex -> cigs
sex -> cp
sex -> thal
thal -> cp
sex -> years
thal -> num.binary
trestbps -> ca
trestbps -> cp
trestbps -> thal
years -> chol
years -> fbs
years -> trestbps
}
')

localTests(g.notbinned,prep,type="cis.chisq", max.conditioning.variables=3)

```
Here, we see low p-values, which indicate that there is not enough evidence to contradict the independence between these variables. However, there are also higher RMSEA values as compared with the binned data. This is because there are too many "categories" compared with the number of samples. The only difference here is that age _||_ sex, whereas, with binned data, this is not the case. Thus, we can conclude that binning the data negatively affects the possibility to prove conditional (in)dependence between these two specific variables. However, the precise reasons for this cannot be stated.

### Inference task
With the created model, we can now perform an inference task. We will be looking at the most contributing variables and predict the variable "num": the presence or absence of heart disease. For this, we first fit the data on the training data.

### Create network and train network with train data
```{r}
#Translate integer columns to numeric (double) columns
train.binary$sex = as.numeric(train.binary$sex)
train.binary$cp = as.numeric(train.binary$cp)
train.binary$fbs = as.numeric(train.binary$fbs)
train.binary$thal = as.numeric(train.binary$thal)
train.binary$ca = as.numeric(train.binary$ca)


net.binary <- model2network(toString(g.binary,"bnlearn"))
plot(g.binary)
head(train.binary)
fit.binary <- bn.fit(net.binary, as.data.frame(train.binary))
fit.binary
```
When looking at these results of fitting the model, we can see that for predicting the presence of heart disease, cardiac fluoroscopy (ca) and chest pain type (cp) are the highest contributing values, as their coefficients have the highest values.

When looking further into the results of the fitting of _ca_ and _cp_, we can state the following:
- For predicting the chest pain type, the thallium stress test results (thal) has the highest contribution;
- For the prediction of the cardiac fluoroscopy results, the age (age.numeric) has the highest contribution.


### Predict the presence of heart disease from test data
After fitting the model on the training data, we will now predict the presence of heart disease ("num") based on (unseen) test data.

```{r}
#Translate integer columns to numeric (double) columns
test.binary$sex = as.numeric(test.binary$sex)
test.binary$cp = as.numeric(test.binary$cp)
test.binary$fbs = as.numeric(test.binary$fbs)
test.binary$thal = as.numeric(test.binary$thal)
test.binary$ca = as.numeric(test.binary$ca)

predict.binary <- data.frame(predict(fit.binary,node="num.binary", data=test.binary))

results.binary = setNames(data.frame(predict.binary), c("predicted"))
results.binary$true=unlist(select(data.frame(test.binary), "num.binary"))
results.binary$predicted_rounded=round(results.binary[,1], digits = 0)
# calculate error
results.binary$error=unlist((results.binary$true-results.binary$predicted_rounded))
#results.binary

```




### Plot Results
The amount of errors - and with this the general accuracy - is visualized below.
```{r}
hist(results.binary$error, )
```
We see a lot of true positives (TPs) and true negatives (TN), indicated with value 0.0. There are around five false negatives (FNs), indicated with value -1.0. There are eight false positives (FPs) indicated with value 1.0.

Below, a confusion matrix showing the TP, TN, FP, and FN is shown. Here, the predicted values are on the left, and the true values are on the top.
```{r}
cm_man.binary <- table(results.binary$predicted_rounded, test.binary$num.binary)
cm_man.binary
```


### Area under the curve - ROC
To see how well our model performs, we use the ROC (Receiver Operator Characteristic) curve. For this curve, the False Positive Rate (FPR) and True Positive Rate (TPR) are plotted against each other. 

The FPR is computed as follows:

FPR = FP / (FP+TN)

The TPR - also called _sensitivity_ is computed as follows:

TPR = TP / (TP + FN)


#### Plot ROC
Below, the ROC curve of the test data is plotted.
```{r}
plot( roc(test.binary$num.binary,results.binary$predicted_rounded) )
```
In an optimal situation, the curve would be a 90-degree corner with 1.0 sensitivity and 1.0 specificity. However, this is rarely the case. 

#### Compute AUC
To get insightful information on the ROC plot, we compute the Area Under the Curve (AUC).


```{r}
auc.binary <- roc(test.binary$num.binary,results.binary$predicted_rounded)
auc.binary
```

Thus, we see that the AUC is 0.7909, which means that model is quite good in discriminating between the abscence or presence of a heart disease.

### AUC of most contributing variables
As mentioned before, chest pain and 

predict(fit.binary, node = "num.binary", data = data.frame(ca), method = "bayes-lw")

We first off look at the results and the confusion matrix of using only those two variables to predict the presence of heart disease.
```{r}


ca <- test.binary$ca
cp <- test.binary$cp
predict.mostContr <- data.frame(predict(fit.binary,node="num.binary", data= data.frame(ca,cp), method = "bayes-lw"))

results.mostContr = setNames(data.frame(predict.mostContr), c("predicted"))
results.mostContr$true=unlist(select(data.frame(test.binary), "num.binary"))
results.mostContr$predicted_rounded=round(results.mostContr[,1], digits = 0)
# calculate error
results.mostContr$error=unlist((results.binary$true-results.binary$predicted_rounded))
#results.mostContr

cm_man.mostContr <- table(results.mostContr$predicted_rounded, test.binary$num.binary)
cm_man.mostContr

```
We see that the results are slightly worse than when using all parents of the target variable. Let's look at the AUC.
```{r}
auc.mostContr <- roc(test.binary$num.binary,results.mostContr$predicted_rounded)
auc.mostContr
```
Thus, we can conclude that even though those two variables contribute a lot in predicting the presence of heart disease, the combination of all parents in the DAG gives better results.

## Normal Model
To see the effect of using binary labels instead of a multi-class classification problem, we included those results. The steps taken are the same as denoted above.
### Draw DAG
```{r}
#Make DAG
g <- dagitty('
dag {
age.numeric [pos="0.262,-1.314"]
ca [pos="-1.351,0.555"]
chol.numeric [pos="-0.728,0.191"]
cigs.numeric [pos="-1.247,-0.466"]
cp [pos="0.348,-0.221"]
fbs [pos="-0.121,0.178"]
num [pos="-0.667,1.153"]
sex [pos="-1.310,-1.357"]
thal [pos="-0.962,0.539"]
trestbps.numeric [pos="-1.247,0.178"]
years.numeric [pos="-0.270,-0.496"]
age.numeric -> cigs.numeric
age.numeric -> years.numeric
age.numeric -> trestbps.numeric
age.numeric -> num
age.numeric -> ca
age.numeric -> chol.numeric
ca -> num
chol.numeric -> num
chol.numeric <-> trestbps.numeric
cigs.numeric -> chol.numeric
cigs.numeric -> cp
cigs.numeric -> fbs
cigs.numeric -> trestbps.numeric
cigs.numeric <-> years.numeric
cp -> num
fbs -> num
sex -> cigs.numeric
sex -> cp
sex -> thal
thal -> cp
sex -> years.numeric
thal -> num
trestbps.numeric -> ca
trestbps.numeric -> cp
trestbps.numeric -> thal
years.numeric -> chol.numeric
years.numeric -> fbs
years.numeric -> trestbps.numeric
}
')
# plot dat
plot(g)

```



### Calculate local test

```{r}
localTests(g,prep,type="cis.chisq", max.conditioning.variables=3)
```
### Create network and train network with test data
```{r}
#Translate integer columns to numeric (double) columns
train$sex = as.numeric(train$sex)
train$cp = as.numeric(train$cp)
train$fbs = as.numeric(train$fbs)
train$thal = as.numeric(train$thal)
train$ca = as.numeric(train$ca)
train$num = as.numeric(train$num)


head(train)

data = select(train, 1,2,3,4,5,6,7,8,9,10,11)

plot(g)
net <- model2network(toString(g,"bnlearn")) 
fit <- bn.fit(net, as.data.frame(data))
fit
```

### Predict num from test data
```{r}
#Translate integer columns to numeric (double) columns
test$sex = as.numeric(test$sex)
test$cp = as.numeric(test$cp)
test$fbs = as.numeric(test$fbs)
test$thal = as.numeric(test$thal)
test$ca = as.numeric(test$ca)
test$num = as.numeric(test$num)

data = select(test, 1,2,3,4,5,6,7,8,9,10,11)

predict <- data.frame(predict(fit,node="num", data=data))

results= setNames(data.frame(predict), c("predicted"))
results$true=unlist(select(data.frame(data), "num"))
results$predicted_rounded=round(results[,1], digits = 0)
# calculate error
results$error=unlist((results$true-results$predicted_rounded))
#results

```




### Plot Results
```{r}
hist(results$error, )
```
calculate true pos and true negative
```{r}
cm_man <- table(results$predicted_rounded, test$num)
cm_man
```


### Area under the curve


#### Plot ROC curve

pot roc
```{r}
plot( roc(test$num,results$predicted_rounded) )
```


#### Get AUC
```{r}
auc <- auc(test$num,results$predicted_rounded)
auc
```

Thus, the results suggest that the results are slightly worse for multi-class classification, as the AUC is lower than for binary classification.
