---
title: "max_project_2"
output: html_document
---

library(dplyr)
library(dagitty)
library(Hmisc)
#library(caTools)
library(bnlearn)
library( pROC )
```


```{r}
#Change the work directory to your location of th data
setwd(getwd())
```


# Importing & Clean Data
Original data is available at https://archive.ics.uci.edu/ml/datasets/Heart+Disease. 
## Import only cleveland data
The original data consist of data from 4 different hospitals in Hungarian, Switserland, Long Beach and Cleveland. In earlier research, the latter is used most research and contains the least missing values of the variables of interest. We thus use this data for our research.
```{r}
# load csv
a.all <- read.csv("data/all_processed.csv",header=TRUE,stringsAsFactors=FALSE) #colClasses=rep("double",4),
d <- read.csv("data/dataCleveland.csv",header=TRUE,stringsAsFactors=FALSE)
```

As missing values are present, we need to clear missing data & and subselect the variables of interest, based on own research. This results in 11 variables (including the target variable). The variables of interest are:
- Age (discrete)
- Sex (binary)
- Chest pain type (categorical) 
- Fasting blood sugar > 120 mg/dl (binary)
- Resting blood pressure (discrete)
- Serum cholesterol in mg/dl (discrete)
- Amount cigarettes/day (discrete)
- Number of years as a smoker (discrete)
- Cardiac fluoroscopy (categorical)
- Thalium stress test (categorical)
- Presence heart disease (categorical)


```{r}
#Select right variables
subset <- select(d, 3,4,9,16,10,12,14,15,44,51,58)

#Filter out mising values
prep <- filter(subset, age != -9 &  sex != -9 & cp != -9 &fbs != -9 & trestbps!= -9 & chol != -9 &cigs != -9 &years!= -9 & ca != -9 &thal != -9 &num!= -9 )
nrow(prep)
nrow(subset)
```




## Process Data
We first take a look at the distribution of the continuous variables of interest
```{r}
hist(prep$age)
hist(prep$chol)
hist(prep$cigs)
hist(prep$years)
hist(prep$trestbps)
```

As we can see, the range of the continuous variables are quite large. As we will use the _localTests_ function to optimize the network, it will use the chi square test. With 272 samples, the chi square test - which treats data as categorical data - introduces sparseness into the data, which is visualized below. Here, the occurences of the combination of all values from age (continuous) and ca (categorical) are shown. 


```{r}
#table( prep$age, prep$ca)
```
Thus, we have more table entries than we have data points, which is a problem for the chi square test. For this reason, we will bin the data of the continuous variables. As we see from the histograms, the variables do not follow a normal distribution. Because of this, we choose an equal amount of samples in each bin. We choose a bin size of 3. 
 
```{r}
#Bin continuous data into categorical data of 3 bins.
amountBins <- 3

continuousVars <- list("age", "chol", "cigs", "years","trestbps")
continuousVars <- unlist(continuousVars)
for(i in 1:length(continuousVars)){
  varname <- continuousVars[i]
  intervalValues.varname <- list()
  intervals.varname <-  names(split(prep, cut2(prep[[varname]], g=amountBins)))
  
  for(j in 1:length(intervals.varname)){
    
    intervals.t <-  unlist(strsplit(intervals.varname[j], ','))
    intervals.fst <- intervals.t[1]
    intervals.snd <- intervals.t[2]
    nc.1 <- nchar(intervals.fst)
    nc.2 <- nchar(intervals.snd)
    intervalValues.varname <- append(intervalValues.varname, as.numeric(substr(intervals.fst,2,nc.1)))
    intervalValues.varname <- append(intervalValues.varname, as.numeric(substr(intervals.snd,1,nc.2-1)))
    
  }
  intervalValues.varname <- unique(unlist(intervalValues.varname))
  intervalValues.varname <- intervalValues.varname[!is.na(intervalValues.varname)]
  intervalValues.varname[1] = intervalValues.varname[1]-1
  intervalValues.varname[length(intervalValues.varname)] = intervalValues.varname[length(intervalValues.varname)]+1
  
  colname.D <-  paste(varname, ".discrete",sep="")
  colname.N <- paste(varname, ".numeric", sep = "")
  prep[colname.D] <- cut( prep[[varname]], breaks=c(intervalValues.varname))
  prep[colname.N] <- as.numeric( prep[[colname.D]])
}

#prep

```

As we want to do an inference task, we split our data into a test- and training dataset.
```{r}
set.seed(13)

#Select only variables we need (numeric)

data <- select(prep, 2,3,4,9,10, 11,13,15,17,19,21)


# split the data 
smp_size = floor(0.75 *  nrow(data))
train_ind <- sample(seq_len(nrow(data)), size = smp_size)
train <-  data[train_ind,]
test <- data[-train_ind,]


#test

```

As the inferences task includes predicting the prevalence of a heart disease, it is important to look at the final label. In this case, it is a multi-classification problem with 4 unique labels. However, as denoted in the background information of the dataset, 0 indicates the absences of a heart disease and [1-4] denote levels of presence of a heart disease. To improve the performance of the inference task, we therefore make it a binary classification problem by merging [1-4] to just value 1. This means that we create a binary test & training dataset
```{r}
num.binary <- prep$num
prep$num.binary <- rapply(as.list(num.binary), function(x) ifelse(x!=0, 1,x), how = "replace")

#Select only variables we need (numeric)
data.binary <- select(prep, 2,3,4,9,10,13,15,17,19,21)
data.binary$num.binary <- as.double(prep[,22])


head(data.binary)
train.binary <-  data.binary[train_ind,]
test.binary <- data.binary[-train_ind,]

#test.binary
```

We then calculate parameters of test and training set.
```{r}
data.neg = sum(data.binary$num.binary==0)
data.pos = sum(data.binary$num.binary==1)
train_neg = sum(train.binary$num.binary==0)
train_pos = sum(train.binary$num.binary==1)
test_neg = sum(test.binary$num.binary==0)
test_pos = sum(test.binary$num.binary==1)
train_pos_perc = train_pos/(train_neg+train_pos)
test_pos_perc = test_pos/(test_neg+test_pos)
data_pos_perc = data.pos/(data.neg+data.pos)
print(train_pos_perc)
print(test_pos_perc)
print(data_pos_perc)
```